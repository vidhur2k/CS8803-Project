{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ofa\n",
    "import ofa.model_zoo\n",
    "import ofa.tutorial\n",
    "import ofa.nas.accuracy_predictor.arch_encoder\n",
    "import ofa.nas.search_algorithm\n",
    "import ofa.nas.efficiency_predictor.latency_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all packages and configured random seed to 1!\n",
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "print('Successfully imported all packages and configured random seed to %d!'%random_seed)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "if cuda_available:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    print('Using GPU.')\n",
    "else:\n",
    "    print('Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OFA Network is ready.\n"
     ]
    }
   ],
   "source": [
    "ofa_network = ofa.model_zoo.ofa_net('ofa_mbv3_d234_e346_k357_w1.2', pretrained=True)\n",
    "#ofa_network = ofa.model_zoo.ofa_net('ofa_resnet50', pretrained=True)\n",
    "print('The OFA Network is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/160_lookup_table.yaml\" to C:\\Users\\andy/.hancai/latency_tools/160_lookup_table.yaml\n",
      "C:\\School\\CS8803-Project\\ofa\\tutorial\\latency_table.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.lut = yaml.load(fp)\n",
      "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/176_lookup_table.yaml\" to C:\\Users\\andy/.hancai/latency_tools/176_lookup_table.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built latency table for image size: 160.\n",
      "Built latency table for image size: 176.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/192_lookup_table.yaml\" to C:\\Users\\andy/.hancai/latency_tools/192_lookup_table.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built latency table for image size: 192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/208_lookup_table.yaml\" to C:\\Users\\andy/.hancai/latency_tools/208_lookup_table.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built latency table for image size: 208.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/224_lookup_table.yaml\" to C:\\Users\\andy/.hancai/latency_tools/224_lookup_table.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built latency table for image size: 224.\n",
      "The Latency lookup table on note10 is ready!\n"
     ]
    }
   ],
   "source": [
    "target_hardware = 'note10'\n",
    "latency_table = ofa.tutorial.LatencyTable(device=target_hardware)\n",
    "print('The Latency lookup table on %s is ready!' % target_hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the path to the ImageNet dataset.\n",
      "\n",
      "C:\\School\\CS8803-Project\\imgnet\n",
      "The ImageNet dataset files are ready.\n"
     ]
    }
   ],
   "source": [
    "if cuda_available:\n",
    "    # path to the ImageNet dataset\n",
    "    print(\"Please input the path to the ImageNet dataset.\\n\")\n",
    "    imagenet_data_path = input()\n",
    "    #imagenet_data_path = 'C:\\School\\once-for-all-master\\imgnet'\n",
    "\n",
    "    # if 'imagenet_data_path' is empty, download a subset of ImageNet containing 2000 images (~250M) for test\n",
    "    if not os.path.isdir(imagenet_data_path):\n",
    "        os.makedirs(imagenet_data_path, exist_ok=True)\n",
    "        ofa.utils.download_url('https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip', model_dir='data')\n",
    "        ! cd data && unzip imagenet_1k 1>/dev/null && cd ..\n",
    "        ! copy -r data/imagenet_1k/* $imagenet_data_path\n",
    "        ! del -rf data\n",
    "        print('%s is empty. Download a subset of ImageNet for test.' % imagenet_data_path)\n",
    "\n",
    "    print('The ImageNet dataset files are ready.')\n",
    "else:\n",
    "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataloader is ready.\n"
     ]
    }
   ],
   "source": [
    "if cuda_available:\n",
    "    # The following function build the data transforms for test\n",
    "    def build_val_transform(size):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
    "            transforms.CenterCrop(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "            root=os.path.join(imagenet_data_path, 'val'),\n",
    "            transform=build_val_transform(224)\n",
    "        ),\n",
    "        batch_size=250,  # test batch size\n",
    "        shuffle=True,\n",
    "        num_workers=16,  # number of workers for the data loader\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    print('The ImageNet dataloader is ready.')\n",
    "else:\n",
    "    data_loader = None\n",
    "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy predictor is ready!\n"
     ]
    }
   ],
   "source": [
    "#accuracy_predictor = ofa.nas.accuracy_predictor.AccuracyPredictor(\n",
    "accuracy_predictor = ofa.tutorial.AccuracyPredictor(\n",
    "    pretrained=True,\n",
    "    device='cuda:0' if cuda_available else 'cpu'\n",
    ")\n",
    "\n",
    "print('The accuracy predictor is ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: search time currently inaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching with note10 constraint (20): 100%|█████████████████████████████████████████████████████████| 500/500 [00:18<00:00, 26.80it/s]\n",
      "Searching with note10 constraint (25): 100%|█████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 28.24it/s]\n",
      "Searching with note10 constraint (30): 100%|█████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 30.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best architecture on note10 with latency <= 20.00 ms in 25.95 seconds! It achieves 80.64% predicted accuracy with 19.82 ms latency on note10.\n",
      "Architecture of the searched sub-net:\n",
      "3x3_Conv_O24_H_SWISH_BN\n",
      "(3x3_MBConv1_RELU_O24_BN, Identity)\n",
      "((O32, E3.0, K3), None)\n",
      "((O32, E3.0, K3), Identity)\n",
      "(SE(O48, E4.0, K3), None)\n",
      "(SE(O48, E6.0, K3), Identity)\n",
      "(SE(O48, E4.0, K3), Identity)\n",
      "((O96, E3.0, K7), None)\n",
      "((O96, E4.0, K5), Identity)\n",
      "((O96, E3.0, K3), Identity)\n",
      "(SE(O136, E4.0, K3), None)\n",
      "(SE(O136, E4.0, K7), Identity)\n",
      "(SE(O136, E4.0, K3), Identity)\n",
      "(SE(O192, E4.0, K3), None)\n",
      "(SE(O192, E6.0, K3), Identity)\n",
      "(SE(O192, E4.0, K3), Identity)\n",
      "(SE(O192, E3.0, K3), Identity)\n",
      "1x1_Conv_O1152_H_SWISH_BN\n",
      "1x1_Conv_O1536_H_SWISH\n",
      "1536x1000_Linear\n",
      "\n",
      "Found best architecture on note10 with latency <= 25.00 ms in 25.95 seconds! It achieves 82.03% predicted accuracy with 24.94 ms latency on note10.\n",
      "Architecture of the searched sub-net:\n",
      "3x3_Conv_O24_H_SWISH_BN\n",
      "(3x3_MBConv1_RELU_O24_BN, Identity)\n",
      "((O32, E3.0, K3), None)\n",
      "((O32, E3.0, K3), Identity)\n",
      "(SE(O48, E4.0, K3), None)\n",
      "(SE(O48, E6.0, K5), Identity)\n",
      "(SE(O48, E4.0, K3), Identity)\n",
      "((O96, E4.0, K7), None)\n",
      "((O96, E4.0, K3), Identity)\n",
      "((O96, E3.0, K3), Identity)\n",
      "((O96, E3.0, K3), Identity)\n",
      "(SE(O136, E4.0, K5), None)\n",
      "(SE(O136, E4.0, K7), Identity)\n",
      "(SE(O136, E4.0, K3), Identity)\n",
      "(SE(O192, E6.0, K3), None)\n",
      "(SE(O192, E6.0, K3), Identity)\n",
      "(SE(O192, E6.0, K3), Identity)\n",
      "(SE(O192, E3.0, K3), Identity)\n",
      "1x1_Conv_O1152_H_SWISH_BN\n",
      "1x1_Conv_O1536_H_SWISH\n",
      "1536x1000_Linear\n",
      "\n",
      "Found best architecture on note10 with latency <= 30.00 ms in 25.95 seconds! It achieves 82.73% predicted accuracy with 29.69 ms latency on note10.\n",
      "Architecture of the searched sub-net:\n",
      "3x3_Conv_O24_H_SWISH_BN\n",
      "(3x3_MBConv1_RELU_O24_BN, Identity)\n",
      "((O32, E4.0, K3), None)\n",
      "((O32, E3.0, K3), Identity)\n",
      "(SE(O48, E4.0, K5), None)\n",
      "(SE(O48, E6.0, K5), Identity)\n",
      "(SE(O48, E4.0, K3), Identity)\n",
      "((O96, E4.0, K7), None)\n",
      "((O96, E4.0, K3), Identity)\n",
      "((O96, E6.0, K3), Identity)\n",
      "((O96, E3.0, K3), Identity)\n",
      "(SE(O136, E6.0, K7), None)\n",
      "(SE(O136, E4.0, K7), Identity)\n",
      "(SE(O136, E4.0, K3), Identity)\n",
      "(SE(O136, E6.0, K3), Identity)\n",
      "(SE(O192, E6.0, K3), None)\n",
      "(SE(O192, E6.0, K3), Identity)\n",
      "(SE(O192, E6.0, K3), Identity)\n",
      "(SE(O192, E3.0, K3), Identity)\n",
      "1x1_Conv_O1152_H_SWISH_BN\n",
      "1x1_Conv_O1536_H_SWISH\n",
      "1536x1000_Linear\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latency_constraint = (20,25,30)  # ms, suggested range [15, 33] ms\n",
    "P = 100  # The size of population in each generation\n",
    "N = 500  # How many generations of population to be searched\n",
    "N2 = 100\n",
    "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
    "params = {\n",
    "    'constraint_type': target_hardware, # Let's do FLOPs-constrained search\n",
    "    'efficiency_constraint': latency_constraint,\n",
    "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
    "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
    "    'efficiency_predictor': latency_table, # To use a predefined efficiency predictor.\n",
    "    'accuracy_predictor': accuracy_predictor, # To use a predefined accuracy_predictor predictor.\n",
    "    'population_size': P,\n",
    "    'max_time_budget': N,\n",
    "    'max_time_budget2': N2,\n",
    "    'parent_ratio': r,\n",
    "}\n",
    "\n",
    "# build the evolution finder\n",
    "finder = ofa.tutorial.EvolutionFinder(**params)\n",
    "\n",
    "# start searching\n",
    "result_lis = []\n",
    "st = time.time()\n",
    "best_valids, best_info = finder.run_evolution_search_multi()\n",
    "for i in range(len(latency_constraint)):\n",
    "    result_lis.append(best_info[i])\n",
    "    ed = time.time()\n",
    "    print('Found best architecture on %s with latency <= %.2f ms in %.2f seconds! '\n",
    "          'It achieves %.2f%s predicted accuracy with %.2f ms latency on %s.' %\n",
    "          (target_hardware, latency_constraint[i], ed-st, best_info[i][0] * 100, '%', best_info[i][-1], target_hardware))\n",
    "\n",
    "    # visualize the architecture of the searched sub-net\n",
    "    _, net_config, latency = best_info[i]\n",
    "    ofa_network.set_active_subnet(ks=net_config['ks'], d=net_config['d'], e=net_config['e'])\n",
    "    print('Architecture of the searched sub-net:')\n",
    "    print(ofa_network.module_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
